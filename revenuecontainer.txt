Executando pela linha de comando um-a-um via Docker...

docker network create net-singular
docker build -t alfecjo/bd-postgres:latest -f Dockerfile.postgres .
docker push alfecjo/bd-postgres:latest
docker run --name postgres -p 5432:5432 -d --network net-singular alfecjo/bd-postgres:1.0
docker exec -it 5f bash
psql -U postgres -d master
\dt
SELECT * FROM VENDAS;
\q
exit
exit
mvn test
_____________________________________________________________________________________________
****MUITO IMPORTANTE -> QUEM FAZ ISSO AGORA É O ****JENKINS****
****MUITO IMPORTANTE -> QUEM FAZ ISSO AGORA É O ****JENKINS****
****MUITO IMPORTANTE -> QUEM FAZ ISSO AGORA É O ****JENKINS****
****MUITO IMPORTANTE -> QUEM FAZ ISSO AGORA É O ****JENKINS****

##### Ver antes o application.properties..

mvn clean package -DskipTests

docker build -t alfecjo/ic-devops:latest .
docker push alfecjo/ic-devops:latest
docker run --name ic-devops -p 8080:8080 -d --network net-singular alfecjo/ic-devops:latest
docker logs e51ee53543abXXXXXXX
_____________________________________________________________________________________________
Executando o Docker Compose...

docker build -t alfecjo/bd-postgres:latest -f Dockerfile.postgres .
docker build -t alfecjo/ic-devops:latest .
docker-compose up
_____________________________________________________________________________________________
Executando pelo Kubernetes

    O kubectl deve estar configurado corretamente para se comunicar com o 
    cluster Kubernetes.
    É possível configurar o kubectl para apontar para o seu cluster EKS 
    executando aws eks update-kubeconfig --name <nome-do-cluster>.

    kubectl Ok!, navegue até o diretório onde os arquivos YAML estão
    localizados.

    comando para implantar os recursos no Kubernetes NESTA ORDEM:

kubectl apply -f postgres-statefulset.yaml
kubectl get statefulset
kubectl apply -f postgres-service.yaml
kubectl apply -f postgres-pod.yaml
kubectl get pod -l app=postgres
kubectl exec -it postgres -- bash
psql -U postgres -d master
\dt
SELECT * FROM VENDAS;
\q
exit
exit

kubectl apply -f contador-vendas-deployment.yaml
kubectl apply -f contador-vendas-service.yaml

****MUITO IMPORTANTE -> recriar a configmap do Prometheus
****MUITO IMPORTANTE -> recriar a configmap do Prometheus
LEMBRANDO QUE PARA EXECUTAR O COMANDO ABAIXO É NECESSÁRIO ESTAR EM \resources OU...
D:\VSCodeWork\contador-vendas\src\main\resources\prometheus.yaml
kubectl create configmap prometheus-config --from-file=prometheus.yml=prometheus.yaml

kubectl apply -f prometheus-pvc.yaml
kubectl get pv
kubectl apply -f prometheus-deployment.yaml
kubectl describe pod
kubectl apply -f prometheus-service.yaml

kubectl apply -f grafana-pvc.yaml
kubectl get pv
kubectl apply -f grafana-deployment.yaml
kubectl describe pod
kubectl apply -f grafana-service.yaml

Após executar esses comandos, o Kubernetes começará a criar os recursos
    especificados nos arquivos YAML. Dá para verificar o status dos recursos
    usando comandos como 
    kubectl get pods
    kubectl get services
    kubectl get deployment

Quando todos os PODs estiverem em estado "Running" e os serviços estiverem 
    disponíveis, sua aplicação e banco de dados estarão em funcionamento
    no cluster Kubernetes.

Localizar a porta que a aplicação está executando:
(Enquanto ñ assimila o command get svc mentalmente. Depois pode firmar a port de dentro do service)
kubectl get svc contador-vendas-service

NAME                      TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
contador-vendas-service   NodePort   10.100.146.15   <none>        8080:31206/TCP   25m

Agora posso executar a pesquisa assim:
  http://localhost:31206/vendas/total-cancelled-sales

ou rodar o ipconfig e resgatar o endereço IPv4(WSL):
   Adaptador Ethernet vEthernet (WSL):

   Sufixo DNS específico de conexão. . . . . . :
   Endereço IPv6 de link local . . . . . . . . : fe80::cd95:4812:e6b6:7dd7%44
   Endereço IPv4. . . . . . . .  . . . . . . . : 172.28.240.1
   Máscara de Sub-rede . . . . . . . . . . . . : 255.255.240.0
   Gateway Padrão. . . . . . . . . . . . . . . :

   http://172.28.240.1:31206/vendas/total-cancelled-sales
_____________________________________________________________________________________________
Se precisar expor uma port para o Prometheus
kubectl port-forward service/prometheus-service 9090:9090

após o comando:
D:\VSCodeWork\contador-vendas (main)                        
λ kubectl port-forward service/prometheus-service 9090:9090 
Forwarding from 127.0.0.1:9090 -> 9090                      
Forwarding from [::1]:9090 -> 9090                          
Handling connection for 9090                                
Handling connection for 9090                                

no Prometheus usei essa url
http://prometheus-service:9090
_____________________________________________________________________________________________
Para verificar algum problema que não foi possível identificar com
kubectl logs contador-vendas-9fffd4bdf-9f78s
(também posso ver os logs pelo DockerDesktop)
kubectl get events
_____________________________________________________________________________________________
acessando o grafana
kubectl get svc grafana-service
                                                                              
:\VSCodeWork\contador-vendas\manifests (main)                                 
 kubectl get svc grafana-service                                              
AME              TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE   
rafana-service   NodePort   10.110.51.52   <none>        80:30735/TCP   9h    
                                                                              
No Chrome
http://localhost:30735/login
admin
admin
_____________________________________________________________________________________________
Opção 1 - Para encerrar os recursos implantados no Kubernetes, você pode usar o comando
 kubectl delete seguido dos arquivos YAML correspondentes aos recursos que você
 implantou.
 (igual a Opção 2 + -f e .yaml para todos!)
 kubectl delete -f contador-vendas-deployment.yaml
 ...

Opção 2 - Para encerrar recursos individualmente: 
kubectl delete service contador-vendas-service
kubectl delete deployment contador-vendas
kubectl delete pod postgres
kubectl delete pvc postgres-data-postgres-statefulset-0
kubectl delete service postgres-service
kubectl delete statefulset postgres-statefulset
kubectl delete pvc prometheus-data
kubectl delete service prometheus-service
kubectl delete deployment prometheus-deployment
kubectl delete pvc grafana-data
kubectl delete service grafana-service
kubectl delete deployment grafana-deployment

ESCALAR/RETORNAR RÉPLICAS
kubectk scale deploy contador-vendas --replicas=n onde n é o número de réplicas...

MOSTRANDO A VERSÃO DO POD BEM COMO AS MUDANÇAS EFETUADAS NA IMAGEM A QUAL SE RELACIONA AO POD
    kubectl rollout history deploy contador-vendas

ALTERANDO A IMAGEM VIA LINHA DE COMANDO (lembrando q dentro do deployment, o campo que temresponsável
pela imagem é o spec:, container:, name:)
    kubectl set image deploy deployment-name img-atual-name=nova-img:version
    kubectl set image deploy contador-vendas contador-vendas=alfecjo/ic-devops:1.8

ALTERANDO PARA REVERTER (undo) A ALTERAÇÃO..
    kubectl rollout undo deploy contador-vendas --to-revision=1
_____________________________________________________________________________________________
JMiter..
Para executar o JMeter no modo de linha de comando (CLI) para testes de carga:
jmeter -n -t [arquivo.jmx] -l [arquivo_resultados.jtl] -e -o [caminho_para_a_pasta_do_relatorio_web]

Criado em d:\VSCodeWork 
jmiter.bat

-n: Modo não GUI (CLI).
-t [arquivo.jmx]: Especifica o arquivo JMX que contém o plano de teste.
-l [arquivo_resultados.jtl]: Especifica o arquivo onde os resultados do teste serão salvos.
-e: Gera o relatório HTML do teste.
-o [caminho_para_a_pasta_do_relatorio_web]: Especifica o diretório onde o relatório HTML será salvo.
_____________________________________________________________________________________________
Jenkins
Para executar o aplicativo, em d:\VSCodeWork:
java -jar jenkins.war e depois, no navegador chame localhost:8080, entre com login e password..

caso haja um arquivo jenkinsfile na raiz do projeto, basta, na configuração do Jenkins
Painel de controle\contador-vendas-pipeline\Configuração em: Pipeline\Definition 
escolher: Pipeline script from SCM, que o jenkinsfile se encarrega do resto...

ou faça o script no próprio Jenkins.. na mesma aba anteriormente citada, escolha: Pipeline script..
_____________________________________________________________________________________________

pipeline {
    agent any
    
    tools {
        maven "mvn"
    }
    
    options {
        timeout(time: 1, unit: 'HOURS')
    }
    
    environment {
        GIT_HEAD = sh(script: 'git rev-parse HEAD', returnStdout: true).trim()
    }
    
    stages {
        stage('Exibir Variáveis de Ambiente') {
            steps {
                sh '''
                    echo "PATH=${PATH}" 
                    echo "M2_HOME=${M2_HOME}" 
                '''
            }
        }
        
        stage('Checkout') {
            steps {
                git branch: 'main', url: 'https://github.com/alfecjo/contador-vendas.git'
            }
        }
        
        stage('Build') {
            steps {
                sh 'mvn clean package'
            }
        }
        
        stage('Test') {
            steps {
                sh 'mvn test'
            }
        }
        
        stage('Deploy') {
            steps {
                echo "IMAGE VERSION: ${GIT_HEAD}"
                script {
                    sh "docker build -t alfecjo/bd-postgres:1.0 -f Dockerfile.postgres ."
                    sh "docker push alfecjo/bd-postgres:1.0"
        
                    sh "docker build -t alfecjo/ic-devops:1.0 ."
                    sh "docker push alfecjo/ic-devops:1.0"
                }
                echo 'Implantação do projeto...'
            }
        }
    }
    
    post {
        always {
            cleanWs()
        }
        
        success {
            echo 'O pipeline foi executado com sucesso!'
        }
        
        failure {
            echo 'O pipeline falhou. Verifique os logs para mais detalhes.'
        }
    }
}

_____________________________________________________________________________________________

depois pode deletar
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus-deployment
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      containers:
        - name: prometheus
          image: prom/prometheus
          ports:
            - containerPort: 9090
          volumeMounts:
            - name: prometheus-data
              mountPath: /prometheus/data
      volumes:
        - name: prometheus-data
          persistentVolumeClaim:
            claimName: prometheus-data