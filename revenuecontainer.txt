Trabalho da disciplina: Integração Contínua e DevOps,
1.	Utilize o Docker para criar uma imagem personalizada de alguma aplicação previamente construída e publique a imagem no Dockerhub.

2.	Suba a imagem em um cluster Kubernetes seguindo as especificações:
    a.	Utilize Deployment para subir a aplicação com 4 réplicas.
    b.	Exponha a aplicação de forma que fique acessível fora do cluster (NODEPORT).
    c.	Para aplicação que fizer uso de banco de dados, crie um POD com o mesmo e deixe acessível através do ClusterIP.
    d.	Crie um probe para a aplicação (Readness ou Liveness).

3.	Crie uma estrutura para monitorar a aplicação com o Prometheus e o Grafana (ou qualquer ferramenta de monitoramento que tenha um servidor de métricas e alguma ferramenta para dashboards).
    a.	Apenas o Grafana deverá ficar acessível para fora do cluster.
    b.	Utilize um PVC para escrever os dados do Prometheus de maneira persistente.
    c.	Crie dashboards do Grafana que exponha dados sensíveis da sua aplicação (memória, cpu, etc...).

4.	Utilize o Jenkins ou qualquer outra ferramenta para criar um pipeline de entrega do projeto.

5.	Execute um stress test do seu projeto e tire print do Dashboard sofrendo alterações.

Resposta:

1. Executando pela linha de comando um-a-um...
docker network create net-singular
docker build -t alfecjo/bd-postgres:1.0 -f Dockerfile.postgres .
docker push alfecjo/bd-postgres:1.0
docker run --name postgres -p 5432:5432 -d --network net-singular alfecjo/bd-postgres:1.0
docker exec -it 5f bash
psql -U postgres -d master
\dt
SELECT * FROM VENDAS;
\q
exit
exit
mvn test

##### Ver antes o application.properties..

mvn clean package -DskipTests

docker build -t alfecjo/ic-devops:1.0 .
docker push alfecjo/ic-devops:1.0
docker run --name ic-devops -p 8080:8080 -d --network net-singular alfecjo/ic-devops:1.7
docker logs e51ee53543abXXXXXXX

2. Executando o Docker Compose...
docker build -t alfecjo/bd-postgres:1.0 -f Dockerfile.postgres .
docker build -t alfecjo/ic-devops:1.0 .
docker-compose up

3. Executando pelo Kubernetes
    a.Certifique-se de que o kubectl esteja configurado corretamente para se comunicar com o seu
    cluster Kubernetes. Você pode configurar o kubectl para apontar para o seu cluster EKS 
    executando aws eks update-kubeconfig --name <nome-do-cluster>.

    b.Depois de configurar o kubectl, navegue até o diretório onde os arquivos YAML estão
    localizados.

Execute o seguinte comando para implantar os recursos no Kubernetes NESTA ORDEM:

kubectl apply -f postgres-statefulset.yaml
kubectl get statefulset
kubectl apply -f postgres-service.yaml
kubectl apply -f postgres-pod.yaml
kubectl get pod -l app=postgres
kubectl exec -it postgres -- bash
psql -U postgres -d master
\dt
SELECT * FROM VENDAS;
\q
exit
exit

kubectl apply -f contador-vendas-deployment.yaml
kubectl apply -f contador-vendas-service.yaml

kubectl apply -f prometheus-pvc.yaml
kubectl get pv
kubectl apply -f prometheus-deployment.yaml
kubectl describe pod
kubectl apply -f prometheus-service.yaml

kubectl apply -f grafana-pvc.yaml
kubectl get pv
kubectl apply -f grafana-deployment.yaml
kubectl describe pod
kubectl apply -f grafana-service.yaml
_____________________________________________________________________________________________
(kubectl port-forward service/prometheus-service 9090:9090)
D:\VSCodeWork\contador-vendas (main)                        
λ kubectl port-forward service/prometheus-service 9090:9090 
Forwarding from 127.0.0.1:9090 -> 9090                      
Forwarding from [::1]:9090 -> 9090                          
Handling connection for 9090                                
Handling connection for 9090                                

no Prometheus usei essa url
http://prometheus-service:9090

kubectl get events

_____________________________________________________________________________________________
acessando o grafana
kubectl get svc grafana-service

                                                                              
:\VSCodeWork\contador-vendas\manifests (main)                                 
 kubectl get svc grafana-service                                              
AME              TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE   
rafana-service   NodePort   10.110.51.52   <none>        80:30735/TCP   9h    
                                                                              
No Chrome
http://localhost:30735/login
admin
admin
_____________________________________________________________________________________________

Para localizar a porta que a aplicação está executando:
kubectl get svc contador-vendas-service

NAME                      TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
contador-vendas-service   NodePort   10.100.146.15   <none>        8080:31206/TCP   25m

Agora posso executar a pesquisa assim:
  http://localhost:31206/vendas/total-cancelled-sales

ou rodar o ipconfig e resgatar o endereço IPv4(WSL):
   Adaptador Ethernet vEthernet (WSL):

   Sufixo DNS específico de conexão. . . . . . :
   Endereço IPv6 de link local . . . . . . . . : fe80::cd95:4812:e6b6:7dd7%44
   Endereço IPv4. . . . . . . .  . . . . . . . : 172.28.240.1
   Máscara de Sub-rede . . . . . . . . . . . . : 255.255.240.0
   Gateway Padrão. . . . . . . . . . . . . . . :

   http://172.28.240.1:31206/vendas/total-cancelled-sales

kubectl get pods

kubectl logs contador-vendas-9fffd4bdf-9f78s
(também posso ver os logs pelo DockerDesktop)

c.Após executar esses comandos, o Kubernetes começará a criar os recursos
    especificados nos arquivos YAML. Você pode verificar o status dos recursos
    usando comandos como kubectl get pods, kubectl get services, etc.

d.Quando todos os PODs estiverem em estado "Running" e os serviços estiverem 
    disponíveis, sua aplicação e banco de dados estarão em funcionamento
    no cluster Kubernetes.

Para acessar sua aplicação, você pode usar o IP e a porta do serviço definido
 no arquivo contador-vendas-service.yaml. Para acessar o banco de dados, você
 pode usar o endereço do serviço PostgreSQL definido no arquivo postgres-service.yaml
 e a porta padrão do PostgreSQL (5432, a menos que tenha sido modificada).

Opção 1 - Para encerrar os recursos implantados no Kubernetes, você pode usar o comando
 kubectl delete seguido dos arquivos YAML correspondentes aos recursos que você
 implantou.
 (igual a Opção 2 + -f e .yaml para todos!)
 kubectl delete -f contador-vendas-deployment.yaml
 ...

Opção 2 - Para encerrar recursos individualmente: 
kubectl delete deployment contador-vendas
kubectl delete service contador-vendas-service
kubectl delete service postgres-service
kubectl delete pod postgres
kubectl delete statefulset postgres-statefulset
kubectl delete pvc postgres-data-postgres-statefulset-0
kubectl delete deployment prometheus-deployment
kubectl delete pvc prometheus-data
kubectl delete service prometheus-service
kubectl delete deployment grafana-deployment
kubectl delete pvc grafana-data
kubectl delete service grafana-service

Isso irá excluir os recursos que foram implantados anteriormente no cluster Kubernetes.
Certifique-se de estar no diretório correto onde os arquivos YAML estão localizados ou
forneça o caminho completo para cada arquivo YAML, se estiver em um diretório diferente.

ESCALAR/RETORNAR RÉPLICAS
kubectk scale deploy contador-vendas --replicas=n onde n é o número de réplicas...

MOSTRANDO A VERSÃO DO POD BEM COMO AS MUDANÇAS EFETUADAS NA IMAGEM A QUAL SE RELACIONA AO POD
    kubectl rollout history deploy contador-vendas

ALTERANDO A IMAGEM VIA LINHA DE COMANDO (lembrando q dentro do deployment, o campo que temresponsável
pela imagem é o spec:, container:, name:)
    kubectl set image deploy deployment-name img-atual-name=nova-img:version
    kubectl set image deploy contador-vendas contador-vendas=alfecjo/ic-devops:1.8

ALTERANDO PARA REVERTER (undo) A ALTERAÇÃO..
    kubectl rollout undo deploy contador-vendas --to-revision=1